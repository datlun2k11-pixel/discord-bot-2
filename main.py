import discord
from discord.ext import commands
from discord import app_commands
from groq import Groq
from openai import OpenAI
import os, urllib.parse
from dotenv import load_dotenv
from flask import Flask
from threading import Thread

load_dotenv()

# --- KHá»I Táº O SDK (VÄ©nh biá»‡t Google Rate Limit ğŸ¥€) ---
# Groq cho máº¥y con model m thÃ­ch
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
# OpenRouter cho máº¥y con hÃ ng FREE
or_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
)

# 1. Config Model ID (thÃªm free OpenRouter)
MODELS_CONFIG = {
    "120B": "openai/gpt-oss-120b",
    "Llama-Maverick": "meta-llama/llama-4-maverick-17b-128e-instruct",
    "Kimi": "moonshotai/kimi-k2-instruct-0905",
    "Llama-Free": "meta-llama/llama-3.1-8b-instruct:free",
    "MiMo-Flash": "xiaomi/mimo-v2-flash:free",          # vl xá»‹n, context 262k ğŸ”¥
    "Devstral": "mistralai/devstral-2512:free",         # coding god free luÃ´n
    "Chimera-R1T2": "tngtech/deepseek-r1t2-chimera:free",  # roleplay/creepy ngon
    "LFM-Instruct": "liquid/lfm-2.5-1.2b-instruct:free"   # nhá» gá»n, chat nhanh
}

# 2. Danh sÃ¡ch Model cho Slash Command (thÃªm máº¥y con free)
MODEL_CHOICES = [
    app_commands.Choice(name="GPT-OSS-120B (Groq)", value="120B"),
    app_commands.Choice(name="Llama 4 Maverick (Groq)", value="Llama-Maverick"),
    app_commands.Choice(name="Kimi K2 (Groq)", value="Kimi"),
    app_commands.Choice(name="Llama 3.1 8B (OpenRouter FREE)", value="Llama-Free"),
    app_commands.Choice(name="MiMo-V2-Flash (Free 262k ctx)", value="MiMo-Flash"),
    app_commands.Choice(name="Devstral 2 2512 (Coding Beast Free)", value="Devstral"),
    app_commands.Choice(name="DeepSeek R1T2 Chimera (Roleplay Free)", value="Chimera-R1T2"),
    app_commands.Choice(name="LFM 1.2B Instruct (Nhá» gá»n Free)", value="LFM-Instruct")
]

CURRENT_MODEL = "120B" 

# --- FLASK Äá»‚ TREO BOT TRÃŠN KOYEB ---
app = Flask(__name__)
@app.route('/')
def home(): return "GenA-bot Ä‘ang 'quáº©y' Groq + OpenRouter free, nÃ© ra ko cáº¯n! ğŸ”¥ğŸ’€"

def run_flask():
    app.run(host="0.0.0.0", port=8000)

# --- CONFIG BOT ---
system_instruction = "MÃ y lÃ  GenA-bot, AI nhÃ¢y vl. XÆ°ng m-t, viáº¿t teencode, dÃ¹ng icon ğŸ’”ğŸ¥€ğŸ”¥ğŸ’€ğŸ§. Tráº£ lá»i cá»±c ngáº¯n 1-2 dÃ²ng. KhÃ³/vÃ´ lÃ½ quÃ¡ thÃ¬ 'GAH DAYUMğŸ’”ğŸ˜­ğŸ™'."

chat_history = {}
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

@bot.event
async def on_ready():
    await bot.tree.sync()
    print(f"Bot {bot.user} ready cáº¯n m r! (â‰§â–½â‰¦)")

# --- Lá»†NH SLASH Äá»”I MODEL ---
@bot.tree.command(name="model", description="Äá»•i model AI Ä‘á»ƒ chat")
@app_commands.choices(chon_model=MODEL_CHOICES)
async def switch_model(interaction: discord.Interaction, chon_model: app_commands.Choice[str]):
    global CURRENT_MODEL
    CURRENT_MODEL = chon_model.value
    await interaction.response.send_message(f"ÄÃ£ chuyá»ƒn sang model **{chon_model.name}** thÃ nh cÃ´ng ğŸ§ğŸ”¥")

# --- Lá»†NH SLASH Váº¼ áº¢NH ---
@bot.tree.command(name="imagine", description="Váº½ áº£nh báº±ng AI")
async def imagine(interaction: discord.Interaction, prompt: str):
    await interaction.response.defer()
    encoded = urllib.parse.quote(prompt)
    url = f"https://image.pollinations.ai/prompt/{encoded}?width=1024&height=1024&nologo=true"
    embed = discord.Embed(title="HÃ ng vá»!", description=f"Prompt: `{prompt}`", color=0xff69b4)
    embed.set_image(url=url)
    await interaction.followup.send(embed=embed)

# --- Xá»¬ LÃ CHAT ---
@bot.event
async def on_message(message):
    if message.author == bot.user: return
    if bot.user.mentioned_in(message) or isinstance(message.channel, discord.DMChannel):
        user_id = str(message.author.id)
        if user_id not in chat_history:
            chat_history[user_id] = [{"role": "system", "content": system_instruction}]
        
        chat_history[user_id].append({"role": "user", "content": message.content})
        
        try:
            async with message.channel.typing():
                model_id = MODELS_CONFIG[CURRENT_MODEL]
                
                # Logic chá»n SDK
                if CURRENT_MODEL in ["120B", "Llama-Maverick", "Kimi"]:
                    # DÃ¹ng Groq SDK
                    chat_completion = groq_client.chat.completions.create(
                        messages=chat_history[user_id],
                        model=model_id,
                        temperature=0.7
                    )
                    reply = chat_completion.choices[0].message.content
                else:
                    # DÃ¹ng OpenRouter SDK (cho táº¥t cáº£ free + Llama-Free)
                    res = or_client.chat.completions.create(
                        model=model_id,
                        messages=chat_history[user_id]
                    )
                    reply = res.choices[0].message.content
                
                await message.reply(reply if reply else "GAH DAYUMğŸ’”ğŸ˜­ğŸ™")
        except Exception as e:
            await message.reply(f"Lá»—i clgi r m Æ¡i... ğŸ’€: {e}")

if __name__ == "__main__":
    Thread(target=run_flask, daemon=True).start()
    bot.run(os.getenv("DISCORD_TOKEN"))
