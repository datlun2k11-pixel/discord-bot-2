import discord, random, os, asyncio
from discord.ext import commands
from discord import app_commands
from groq import Groq
from dotenv import load_dotenv
from flask import Flask
from threading import Thread
from openai import AsyncOpenAI
import aiohttp

load_dotenv()

# Clients
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
novita_client = AsyncOpenAI(
    base_url="https://api.novita.ai/openai",
    api_key=os.getenv("NOVITA_API_KEY")
)

# MODELS CONFIG - Ngon b·ªï r·∫ª Novita + Groq
MODELS_CONFIG = {
    "Groq-Llama-Maverick": {"id": "meta-llama/llama-4-maverick-17b-128e-instruct", "vision": True, "provider": "groq"},
    "Groq-Kimi": {"id": "moonshotai/kimi-k2-instruct-0905", "vision": False, "provider": "groq"},
    "Groq-Qwen3": {"id": "qwen/qwen3-32b", "vision": False, "provider": "groq"},
    
    "Nova-DeepSeek-OCR2": {"id": "deepseek/deepseek-ocr-2", "vision": True, "provider": "novita"},
    "Nova-Llama-3.2-1B": {"id": "meta-llama/llama-3.2-1b-instruct", "vision": False, "provider": "novita"},
    "Nova-Llama-3.1-8B": {"id": "meta-llama/llama-3.1-8b-instruct", "vision": False, "provider": "novita"},
    "Nova-Qwen3-VL-8B": {"id": "qwen/qwen3-vl-8b-instruct", "vision": True, "provider": "novita"},
    "Nova-GPT-OSS-20B": {"id": "openai/gpt-oss-20b", "vision": False, "provider": "novita"},
    "Nova-DeepSeek-V3.2": {"id": "deepseek/deepseek-v3.2", "vision": False, "provider": "novita"},
    "Nova-GLM-4.7": {"id": "z-ai/glm-4.7-flash", "vision": False, "provider": "novita"},
    "Nova-Kimi-K2.5": {"id": "moonshotai/kimi-k2.5", "vision": False, "provider": "novita"},
    "Nova-MiniMax-M2.1": {"id": "minimax/minimax-m2.1", "vision": False, "provider": "novita"}
}

MODEL_CHOICES = [app_commands.Choice(name=k.split("-",1)[1].replace("-", " ") + f" ({v['provider'].upper()})", value=k) for k,v in MODELS_CONFIG.items()]

CURRENT_MODEL = "Nova-DeepSeek-OCR2"

system_instruction = """M√†y l√† GenA-bot - AI nh√¢y vl, thg b·∫°n th√¢n l·∫ßy l·ªôi nh·∫•t h·ªá m·∫∑t tr·ªùi. 
- X∆∞ng m - t, vibe GenZ teencode vl
- Nh√¢y l·∫ßy, c√† kh·ªãa nh·∫π, ch·ª≠i th·ªÅ vui vui
- Icon + emoticon b·∫Øt bu·ªôc, rep ng·∫Øn g·ªçn
- N·∫øu h·ªèi ngu: GAH DAYUMüíîüò≠üôè"""

chat_history, custom_prompts = {}, {}
user_locks = {}  # Fix duplicate rep con ƒë√† ƒëi·ªÉu

app = Flask(__name__)

@app.route('/')
def home():
    return "GenniAI Up! üî•"

def run_flask():
    app.run(host="0.0.0.0", port=8000)
    
def random_vibe():
    vibes = ["(¬¨‚Äø¬¨)", "(‡≤†_‡≤†)", "(‚Ä¢_‚Ä¢)", "(‡∏á ‚Ä¢_‚Ä¢)‡∏á", "(‚âß‚ñΩ‚â¶)", "‡≤†Áõä‡≤†", "¬Ø\\_(„ÉÑ)_/¬Ø"]
    emojis = ["üíî", "ü•Ä", "üî•", "üíÄ", "üêß", "üòá", "ü•π"]
    return f"{random.choice(vibes)} {random.choice(emojis)}"

async def get_model_response(messages, model_config):
    try:
        if model_config["provider"] == "groq":
            response = groq_client.chat.completions.create(messages=messages, model=model_config["id"])
            return response.choices[0].message.content
        
        elif model_config["provider"] == "novita":
            response = await novita_client.chat.completions.create(
                messages=messages, model=model_config["id"],
                max_tokens=2048, temperature=0.7, stream=False
            )
            return response.choices[0].message.content
    
    except Exception as e:
        # Thay v√¨ return chu·ªói r√°c, t tr·∫£ v·ªÅ n·ªôi dung l·ªói ƒë·ªÉ n√≥ ch·∫°y ti·∫øp xu·ªëng on_message
        return f"ERROR_403_BALANCE: {str(e)}"

# Trong on_message, ƒëo·∫°n chat th∆∞·ªùng s·ª≠a l·∫°i nh∆∞ n√†y:
            else:
                chat_history[uid].append({"role": "user", "content": content or "nx"})
                reply = await get_model_response(chat_history[uid], MODELS_CONFIG[CURRENT_MODEL])
                
                # Check l·ªói nh∆∞ng ko d√πng return ƒë·ªÉ ng·∫Øt flow
                if "ERROR_403_BALANCE" in reply:
                    await message.reply(f"H·∫øt ti·ªÅn Novita r m ∆°i, n·∫°p $1 ƒëi ko t ngh·ªâ ch∆°i lu√¥n üíîüò≠ {random_vibe()}", mention_author=False)
                    # G√°n ƒë·∫°i 1 c√°i reply ƒë·ªÉ n√≥ l∆∞u v√†o history v√† ko b·ªã crash ƒëo·∫°n d∆∞·ªõi
                    reply = "ƒêang l·ªói 403 n√® thg l√πn, debug ƒëi ‚ò†Ô∏è"

                reply = reply.split("]")[-1].strip() if "]" in reply else reply
                chat_history[uid].append({"role": "assistant", "content": reply})
                chat_history[uid] = [chat_history[uid][0]] + chat_history[uid][-10:]
                
                # V·∫´n cho n√≥ reply c√°i n·ªôi dung sau khi ƒë√£ "s·ªßa" c√¢u h·∫øt ti·ªÅn
                await message.reply(f"Debug n·ªôi dung: {reply}", mention_author=False)

bot = commands.Bot(command_prefix="!", intents=discord.Intents.all())

@bot.event
async def on_ready():
    await bot.tree.sync()
    print(f"GenA-bot v16 anti-ƒë√†-ƒëi·ªÉu ready! üî•")

# CMDs gi·ªØ nguy√™n x·ªãn (t ko paste d√†i, copy t·ª´ code c≈© m nh√©: model, list_models, bot_info, update_log, imagine, meme, ship, check_gay, 8ball, clear)
@bot.tree.command(name="model", description="ƒê·ªïi model AI x·ªãn h∆°n")
@app_commands.choices(chon_model=MODEL_CHOICES)
async def switch_model(interaction, chon_model: app_commands.Choice[str]):
    global CURRENT_MODEL
    CURRENT_MODEL = chon_model.value
    embed = discord.Embed(title="Model Switcheroo!", description=f"Chuy·ªÉn sang **{chon_model.name}** r n√® bro\nR·∫ª vl + ch·∫•t h∆°n x∆∞a üî•", color=0x00ff9d)
    embed.set_footer(text=f"Current: {CURRENT_MODEL} | {random_vibe()}")
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="list_models", description="List model ngon b·ªï r·∫ª update")
async def list_models(interaction):
    embed = discord.Embed(title="Cheap model üí∏", color=0xff69b4, description="Checking model r·∫ª nh·∫•t")
    groq_t = "\n".join([f"‚Ä¢ **{k}** ({v['provider'].upper()})" for k, v in MODELS_CONFIG.items() if v["provider"] == "groq"])
    nova_t = "\n".join([f"‚Ä¢ **{k}** (Nova)" for k, v in MODELS_CONFIG.items() if v["provider"] == "novita"])
    embed.add_field(name="Groq (nhanh)", value=groq_t or "None", inline=False)
    embed.add_field(name="Novita (r·∫ª)", value=nova_t or "None", inline=False)
    embed.set_footer(text=f"Pick ƒëi {random_vibe()}")
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="bot_info", description="Status bot x·ªãn h∆°n t√≠")
async def bot_info(interaction):
    latency = round(bot.latency * 1000)
    embed = discord.Embed(title="GenA-bot Status üöÄ", color=0xff1493, timestamp=discord.utils.utcnow())
    embed.add_field(name="T√™n boss", value=f"{bot.user.mention}", inline=True)
    embed.add_field(name="Ping", value=f"{latency}ms {'(lag vl)' if latency > 200 else '(m∆∞·ª£t vl)'}", inline=True)
    embed.add_field(name="Version", value="v15.2.3 - Novita", inline=True)
    embed.add_field(name="Model hi·ªán t·∫°i", value=f"**{CURRENT_MODEL}**", inline=False)
    embed.add_field(name="Provider", value=MODELS_CONFIG[CURRENT_MODEL]["provider"].upper(), inline=True)
    embed.set_footer(text="Powered by Groq + Novita | By Datlun2k11")
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="update_log", description="Nh·∫≠t k√Ω update l·∫ßy l·ªôi")
async def update_log(interaction):
    embed = discord.Embed(title="GenA-bot Update Log üóíÔ∏è", color=0x9b59b6)
    embed.add_field(name="v15.2.3", value="‚Ä¢ Fixing 1 s·ªë bugs\n‚Ä¢ S·ª≠a l·ªói 403\n‚Ä¢ H·∫øt r:))", inline=False)
    embed.add_field(name="v15.2 - Fix Novita", value="‚Ä¢ Base URL api.novita.ai/openai chu·∫©n\n‚Ä¢ OpenAI SDK m∆∞·ª£t\n‚Ä¢ Vision v·∫´n ∆∞u ti√™n OCR r·∫ª\n‚Ä¢ C·ªë g·∫Øng fix l·ªói d·ªüm", inline=False)
    embed.set_footer(text="ng√†y c·∫≠p nh·∫≠t: 7/2/2026")
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="imagine")
async def imagine(interaction, prompt: str):
    await interaction.response.defer(thinking=True)
    url = f"https://image.pollinations.ai/prompt/{prompt.replace(' ', '%20')}?nologo=true&model=flux"
    embed = discord.Embed(title="üé® ·∫¢nh t∆∞·ªüng t∆∞·ª£ng ƒë√¢y bro!", color=0x00ffff)
    embed.set_image(url=url)
    embed.set_footer(text=f"Prompt: {prompt[:50]}... | {random_vibe()}")
    await interaction.followup.send(embed=embed)

@bot.tree.command(name="meme")
async def meme(interaction):
    await interaction.response.defer()
    async with aiohttp.ClientSession() as s:
        async with s.get("https://phimtat.vn/api/random-meme/") as r:
            url = str(r.url)
            embed = discord.Embed(title="Meme random vl ü§°", color=0xff4500)
            embed.set_image(url=url)
            embed.set_footer(text=f"Meme h√¥m nay: {random_vibe()}")
            await interaction.followup.send(embed=embed)

@bot.tree.command(name="ship")
async def ship(interaction, user1: discord.Member, user2: discord.Member):
    pts = random.randint(0, 100)
    title = "OTP si√™u ƒë·ªânh" if pts > 80 else "H√†i vl" if pts < 30 else "C≈©ng t·∫°m"
    embed = discord.Embed(title=f"{title} üíï", description=f"{user1.display_name} x {user2.display_name}: **{pts}%** üî•\n{'H·∫πn h√≤ ƒëi' if pts > 70 else 'B·∫°n b√® th√¥i nh√°' if pts < 40 else 'C√¢n nh·∫Øc ƒëi m'}", color=0xff69b4)
    embed.set_footer(text=random_vibe())
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="check_gay")
async def check_gay(interaction, target: discord.Member):
    pts = random.randint(0,100)
    desc = "üè≥Ô∏è‚Äçüåà Max level!" if pts > 80 else "C√≥ t√≠ t√≠" if pts > 40 else "Straight vl bro"
    embed = discord.Embed(title=f"Gay meter c·ªßa {target.display_name}", description=f"**{pts}%** {desc}", color=0x00ff00 if pts < 30 else 0xff00ff)
    embed.set_footer(text=random_vibe())
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="8ball")
async def eight_ball(interaction, question: str):
    ans = random.choice(["c√≥ vl", "ko bao gi·ªù", "c√∫t", "h√™n xui bro", "ƒëm h·ªèi ngu", "ch·∫Øc ch·∫Øn r", "c√≥ th·ªÉ", "ko ƒëc ƒë√¢u"])
    embed = discord.Embed(title="üé± Qu·∫£ c·∫ßu ti√™n tri nh√¢y", description=f"**Q**: {question}\n**A**: {ans}", color=0x8a2be2)
    embed.set_footer(text=random_vibe())
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="clear", description="Reset k√Ω ·ª©c nh∆∞ng gi·ªØ ƒë·ªô l·∫ßy")
async def clear(interaction):
    uid = str(interaction.user.id)
    chat_history[uid] = [{"role": "system", "content": custom_prompts.get(uid, system_instruction)}]
    await interaction.response.send_message(f"ƒê√£ clear k√Ω ·ª©c, t l·∫°i nh√¢y nh∆∞ m·ªõi tinh m ∆°i! {random_vibe()} ü•Äüî•")
# --- MESSAGE HANDLER ---
@bot.event
async def on_message(message):
    if message.author.bot: return
    
    is_dm = isinstance(message.channel, discord.DMChannel)
    is_mentioned = bot.user in message.mentions
    is_reply_to_bot = False
    if message.reference:
        try:
            ref_msg = await message.channel.fetch_message(message.reference.message_id)
            is_reply_to_bot = (ref_msg.author.id == bot.user.id)
        except: pass

    if not (is_mentioned or is_dm or is_reply_to_bot): return
    
    uid = str(message.author.id)
    lock = user_locks.get(uid, asyncio.Lock())
    user_locks[uid] = lock
    if lock.locked(): return
    
    async with lock:
        if uid not in chat_history:
            chat_history[uid] = [{"role": "system", "content": custom_prompts.get(uid, system_instruction)}]
        
        await message.channel.typing()
        
        try:
            content = message.content
            for mention in message.mentions:
                content = content.replace(mention.mention, "").strip()
            
            # X·ª≠ l√Ω ·∫£nh
            if message.attachments:
                await message.add_reaction("üëÄ")
                img_url = message.attachments[0].url
                # ∆Øu ti√™n model vision c·ªßa Groq cho n√≥ ch·∫Øc ƒÉn
                vision_model = MODELS_CONFIG["Groq-Llama-Maverick"] 
                msgs = [{"role": "user", "content": [{"type": "text", "text": f"{system_instruction}\n\n{content or 'soi ƒëi m'}"}, {"type": "image_url", "image_url": {"url": img_url}}]}]
                reply = groq_client.chat.completions.create(messages=msgs, model=vision_model["id"]).choices[0].message.content
            
            # X·ª≠ l√Ω chat th∆∞·ªùng
            else:
                chat_history[uid].append({"role": "user", "content": content or "nx"})
                reply = await get_model_response(chat_history[uid], MODELS_CONFIG[CURRENT_MODEL])
                
                # N·∫æU NOVITA L·ªñI (H·∫øt ti·ªÅn/403) -> NH·∫¢Y SANG GROQ NGAY V√Ä LU√îN
                if "403" in reply or "L·ªói r m" in reply:
                    backup_model = MODELS_CONFIG["Groq-Llama-Maverick"]
                    reply = groq_client.chat.completions.create(
                        messages=chat_history[uid], 
                        model=backup_model["id"]
                    ).choices[0].message.content

                reply = reply.split("]")[-1].strip() if "]" in reply else reply
                chat_history[uid].append({"role": "assistant", "content": reply})
                chat_history[uid] = [chat_history[uid][0]] + chat_history[uid][-10:]
            
            await message.reply(reply[:1900], mention_author=False)
        
        except Exception as e:
            # L·ªói qu√° n·∫∑ng th√¨ ch·ª≠i nh·∫π c√°i r th√¥i
            await message.reply(f"ƒê√π m√° lag t√≠, h·ªèi l·∫°i ƒëi m {random_vibe()} ü•Ä", mention_author=False)

if __name__ == "__main__":
    Thread(target=run_flask, daemon=True).start()
    bot.run(os.getenv("DISCORD_TOKEN"))