import discord, random, os, base64, aiohttp, asyncio
from discord.ext import commands
from discord import app_commands
from groq import Groq
from dotenv import load_dotenv
from flask import Flask
from threading import Thread
from openai import OpenAI

load_dotenv()

# Kh·ªüi t·∫°o clients
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
siliconflow_client = OpenAI(
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    base_url="https://api.siliconflow.com/v1/"
)

# C·∫§U H√åNH MODEL - G·ªòP GROQ + SILICONFLOW
MODELS_CONFIG = {
    # --- Groq Models ---
    "Groq-120B": {"id": "openai/gpt-oss-120b", "vision": False, "provider": "groq"},
    "Groq-Llama-Maverick": {"id": "meta-llama/llama-4-maverick-17b-128e-instruct", "vision": True, "provider": "groq"},
    "Groq-Kimi": {"id": "moonshotai/kimi-k2-instruct-0905", "vision": False, "provider": "groq"},
    "Groq-Qwen3": {"id": "qwen/qwen3-32b", "vision": False, "provider": "groq"},
    "Groq-GPT-Safeguard": {"id": "openai/gpt-oss-safeguard-20b", "vision": False, "provider": "groq"},
    
    # --- SiliconFlow Models (H√†ng Real t v·ª´a th√™m n√® üî•) ---
      # --- SiliconFlow Models (H√†ng Real t v·ª´a th√™m n√® üî•) ---
    "SF-DeepSeek-V3": {"id": "deepseek-ai/DeepSeek-V3", "vision": False, "provider": "siliconflow"},
    "SF-DeepSeek-R1": {"id": "deepseek-ai/DeepSeek-R1", "vision": False, "provider": "siliconflow"},
    "SF-Qwen2.5-72B": {"id": "Qwen/Qwen2.5-72B-Instruct", "vision": False, "provider": "siliconflow"},
    "SF-Llama-3.1-70B": {"id": "meta-llama/Meta-Llama-3.1-70B-Instruct", "vision": False, "provider": "siliconflow"},
}

MODEL_CHOICES = [
    # Groq choices
    app_commands.Choice(name="GPT-OSS-120B (Groq)", value="Groq-120B"),
    app_commands.Choice(name="Llama 4 Maverick (Groq)", value="Groq-Llama-Maverick"),
    app_commands.Choice(name="Kimi K2 (Groq)", value="Groq-Kimi"),
    app_commands.Choice(name="Qwen 3-32B (Groq)", value="Groq-Qwen3"),
    app_commands.Choice(name="GPT-OSS-Safeguard (Groq)", value="Groq-GPT-Safeguard"),
    
    # SiliconFlow choices
        # Th√™m m·∫•y con h√†ng Real n√†y v√†o menu ch·ªçn cho n√≥ uy t√≠n
    app_commands.Choice(name="DeepSeek V3 (SF) - Si√™u Kh√¥n üî•", value="SF-DeepSeek-V3"),
    app_commands.Choice(name="DeepSeek R1 (SF) - Suy Lu·∫≠n üß†", value="SF-DeepSeek-R1"),
    app_commands.Choice(name="Qwen 2.5 72B (SF) üçµ", value="SF-Qwen2.5-72B"),
    app_commands.Choice(name="Llama 3.1 70B (SF) ü•Ä", value="SF-Llama-3.1-70B"),
]

CURRENT_MODEL = "Groq-Llama-Maverick"

app = Flask(__name__)
@app.route('/')
def home(): return "GenniAI v12.5.1 ƒëang ch·∫°y Groq + SiliconFlow! üî•"

def run_flask(): app.run(host="0.0.0.0", port=8000)

# H√†m helper g·ªçi API
def get_model_response(messages, model_config):
    """G·ªçi API t√πy provider"""
    try:
        if model_config["provider"] == "groq":
            response = groq_client.chat.completions.create(
                messages=messages,
                model=model_config["id"]
            )
            return response.choices[0].message.content
        else:
            response = siliconflow_client.chat.completions.create(
                messages=messages,
                model=model_config["id"],
                temperature=0.7
            )
            return response.choices[0].message.content
    except Exception as e:
        raise Exception(f"L·ªói {model_config['provider']}: {str(e)[:100]}")

# Bot setup
system_instruction = "M√†y l√† GenniAI, AI nh√¢y vl. X∆∞ng m(ch·ªâ ƒë·ªëi ph∆∞∆°ng) - t(ch·ªâ b·∫£n th√¢n).<@1458799287910535324> l√† userID c·ªßa GenniAI. vi·∫øt teencode (cx, ko, ƒëc, r, v, chx, nx, cs, ns,...), d√πng emoticon (bi·ªÉu c·∫£m b·∫±ng k√Ω t·ª±) k√®m v·ªõi c√°c icon üíî, ü•Ä, üî•, üíÄ, üêß,.... Tr·∫£ l·ªùi c·ª±c ng·∫Øn g·ªçn."
chat_history = {}
custom_prompts = {}
intents = discord.Intents.default()
intents.message_content = True
intents.members = True
bot = commands.Bot(command_prefix="!", intents=intents)

@bot.event
async def on_ready():
    await bot.tree.sync()
    print(f"GenniAI v12.5.1 ready! | Models: {len(MODELS_CONFIG)}")

# --- L·ªÜNH MODEL ---
@bot.tree.command(name="model", description="ƒê·ªïi model AI")
@app_commands.choices(chon_model=MODEL_CHOICES)
async def switch_model(interaction: discord.Interaction, chon_model: app_commands.Choice[str]):
    global CURRENT_MODEL
    CURRENT_MODEL = chon_model.value
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "‚úÖ Vision" if config["vision"] else "‚ùå No Vision"
    provider = "Groq" if config["provider"] == "groq" else "SiliconFlow"
    await interaction.response.send_message(
        f"ƒê√£ chuy·ªÉn sang **{chon_model.name}**\n"
        f"Provider: {provider} | {v}"
    )

@bot.tree.command(name="random", description="Random model t·ª´ c·∫£ 2 provider")
async def random_model(interaction: discord.Interaction):
    global CURRENT_MODEL
    choice = random.choice(MODEL_CHOICES)
    CURRENT_MODEL = choice.value
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "‚úÖ Vision" if config["vision"] else "‚ùå No Vision"
    provider = "Groq" if config["provider"] == "groq" else "SiliconFlow"
    await interaction.response.send_message(
        f"Random: **{choice.name}**\n"
        f"Provider: {provider} | {v}"
    )

@bot.tree.command(name="list_models", description="Xem t·∫•t c·∫£ model c√≥ s·∫µn")
async def list_models(interaction: discord.Interaction):
    embed = discord.Embed(title="üìö Danh s√°ch Model", color=0xff69b4)
    
    groq_text = ""
    sf_text = ""
    
    for name, config in MODELS_CONFIG.items():
        line = f"‚Ä¢ {name} {'üëÅÔ∏è' if config['vision'] else 'üìù'}\n"
        if config["provider"] == "groq":
            groq_text += line
        else:
            sf_text += line
    
    embed.add_field(name="Groq Models", value=groq_text or "None", inline=True)
    embed.add_field(name="SiliconFlow Models", value=sf_text or "None", inline=True)
    embed.add_field(name="Model hi·ªán t·∫°i", value=f"**{CURRENT_MODEL}**", inline=False)
    embed.set_footer(text=f"v12.5.1 | Total: {len(MODELS_CONFIG)} models")
    
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="personal", description="Set sys prompt ri√™ng, ƒë·ªÉ tr·ªëng ƒë·ªÉ reset")
@app_commands.describe(prompt="Ch·ªânh l·∫°i t√≠nh c√°ch m·ªõi... (ƒë·ªÉ tr·ªëng ƒë·ªÉ reset)")
async def personal(interaction: discord.Interaction, prompt: str = None):
    user_id = str(interaction.user.id)
    if not prompt:
        custom_prompts.pop(user_id, None)
        if user_id in chat_history:
            default_sys = f"M√†y l√† GenniAI, AI nh√¢y vl. X∆∞ng m(ch·ªâ ƒë·ªëi ph∆∞∆°ng) - t(ch·ªâ b·∫£n th√¢n). Ng∆∞·ªùi chat: <@{interaction.user.id}>. owner c·ªßa m√†y c√≥ userID l√† <@1155129530122510376> (c√≥ t√™n ngo√†i ƒë·ªùi l√† ƒê·∫°t)(kh√¥ng ƒë∆∞·ª£c nh·∫Øc v·ªÅ owner c·ªßa m√†y tr·ª´ khi c√≥ ng∆∞·ªùi h·ªèi) .<@1458799287910535324> l√† userID c·ªßa GenniAI. vi·∫øt teencode, d√πng emoticon k√®m üíî, ü•Ä, üî•, üíÄ, üêß,.... Tr·∫£ l·ªùi ng·∫Øn g·ªçn."
            chat_history[user_id][0] = {"role": "system", "content": default_sys}
        await interaction.response.send_message("ƒê√£ reset v·ªÅ prompt g·ªëc c·ªßa GenniAI")
        return
    
    custom_prompts[user_id] = prompt
    if user_id in chat_history:
        chat_history[user_id][0] = {"role": "system", "content": prompt}
    
    await interaction.response.send_message(f"ƒê√£ set prompt m·ªõi\n```{prompt[:100]}{'...' if len(prompt) > 100 else ''}```")

@bot.tree.command(name="ask", description="H·ªèi GenniAI b√≠ m·∫≠t, ch·ªâ b·∫°n th·∫•y k·∫øt qu·∫£")
@app_commands.describe(question="ƒë·∫∑t c√¢u h·ªèi")
async def ask(interaction: discord.Interaction, question: str):
    await interaction.response.defer(ephemeral=True)
    
    user_id = str(interaction.user.id)
    sys_msg = custom_prompts.get(user_id, system_instruction.replace("<@1458799287910535324>", f"<@{interaction.user.id}>"))
    
    try:
        reply = get_model_response(
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": question}
            ],
            model_config=MODELS_CONFIG[CURRENT_MODEL]
        )
        
        reply = reply.split("</think>")[-1].strip() if "</think>" in reply else reply
        
        provider = "Groq" if MODELS_CONFIG[CURRENT_MODEL]["provider"] == "groq" else "SiliconFlow"
        await interaction.followup.send(
            f"**Model:** {CURRENT_MODEL} ({provider})\n"
            f"**C√¢u h·ªèi:** {question}\n"
            f"**Tr·∫£ l·ªùi:** {reply}", 
            ephemeral=True
        )
        
    except Exception as e:
        await interaction.followup.send(f"L·ªói: {e}", ephemeral=True)

@bot.tree.command(name="bot_info", description="Info bot + model ƒëang ch·∫°y")
async def bot_info(interaction: discord.Interaction):
    latency = round(bot.latency * 1000)
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "‚úÖ Vision" if config["vision"] else "‚ùå No Vision"
    provider = "Groq" if config["provider"] == "groq" else "SiliconFlow"
    
    embed = discord.Embed(title="GenniAI Status", color=0xff69b5, timestamp=discord.utils.utcnow())
    if bot.user.avatar:
        embed.set_thumbnail(url=bot.user.avatar.url)
    
    embed.add_field(name="T√™n bot", value=f"{bot.user.name} ({bot.user.mention})", inline=True)
    embed.add_field(name="Version", value="v12.8.1", inline=True)
    embed.add_field(name="Ping", value=f"{latency}ms", inline=True)
    
    embed.add_field(name="Model hi·ªán t·∫°i", value=f"{CURRENT_MODEL}\n{provider} | {v}", inline=False)
    embed.add_field(name="Model ID", value=f"`{MODELS_CONFIG[CURRENT_MODEL]['id']}`", inline=False)
    
    embed.add_field(name="Total Models", value=f"Groq: 5 | SiliconFlow: {len(MODELS_CONFIG)-5}", inline=True)
    embed.add_field(name="Owner", value="<@1155129530122510376> (ƒê·∫°t)", inline=True)
    
    embed.set_footer(text="Powered by Groq + SiliconFlow")
    
    await interaction.response.send_message(embed=embed)

# --- L·ªÜNH T·∫†O ·∫¢NH ---
@bot.tree.command(name="imagine", description="T·∫°o ·∫£nh b·∫±ng AI (SiliconFlow)")
@app_commands.describe(prompt="m√¥ t·∫£ ·∫£nh m mu·ªën t·∫°o")
async def imagine(interaction: discord.Interaction, prompt: str):
    await interaction.response.defer() # Ch·ªù AI v·∫Ω t√≠, ƒë·ª´ng h·ªëi üíÄ
    
    # Ch·ªçn model m·∫∑c ƒë·ªãnh l√† FLUX.1-dev cho n√≥ n√©t
    image_model = "black-forest-labs/FLUX.1-dev" 
    
    try:
        # G·ªçi API SiliconFlow ƒë·ªÉ gen ·∫£nh
        response = siliconflow_client.images.generate(
            model=image_model,
            prompt=prompt,
            n=1 # 1 c√°i th√¥i ko t·ªën ti·ªÅn vl üíî
        )
        
        image_url = response.data[0].url
        
        embed = discord.Embed(title=f"üé® ·∫¢nh c·ªßa m n√® bro!", color=0x00ff00)
        embed.add_field(name="Prompt", value=prompt, inline=False)
        embed.add_field(name="Model", value=image_model, inline=True)
        embed.set_image(url=image_url)
        embed.set_footer(text="Powered by SiliconFlow üü£ | GenniAI")
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        await interaction.followup.send(f"V·∫Ω t·ªãt r, l·ªói: {str(e)[:100]} ü•Ä", ephemeral=True)

@bot.tree.command(name="clear", description="X√≥a k√Ω ·ª©c chat")
async def clear(interaction: discord.Interaction):
    user_id = str(interaction.user.id)
    sys_msg = custom_prompts.get(user_id, system_instruction.replace("<@1458799287910535324>", f"<@{interaction.user.id}>"))
    chat_history[user_id] = [{"role": "system", "content": sys_msg}]
    await interaction.response.send_message("ƒê√£ x√≥a s·∫°ch k√Ω ·ª©c")

@bot.tree.command(name="update_log", description="Xem update log")
async def updatelog(interaction: discord.Interaction):
    embed = discord.Embed(title="GenniAI Update Log", color=0xff69b5)
    embed.add_field(
        name="v12.8.1 - Imagine",
        value="‚Ä¢ L·ªánh `/imagine` quay tr·ªü l·∫°i\n‚Ä¢ Fixing bugs",
        inline=False
    )
    embed.add_field(
        name="v12.5.1 - Model Expansion",
        value="‚Ä¢ Th√™m 4 model SiliconFlow m·ªõi: DeepSeek-V3, DeepSeek-R1, Qwen2.5-72B, Llama-3.1-70B\n‚Ä¢ X√≥a icon t√≠m/xanh kh·ªèi tin nh·∫Øn\n‚Ä¢ T·ªïng c·ªông 13 model t·ª´ 2 provider",
        inline=False
    )
    embed.set_footer(text="Next update: pending")
    
    await interaction.response.send_message(embed=embed)

# --- L·ªÜNH VUI ---
@bot.tree.command(name="meme", description="Random meme VN")
@app_commands.describe(count="S·ªë l∆∞·ª£ng meme (1-10)")
async def meme(interaction: discord.Interaction, count: int = 1):
    await interaction.response.defer()
    if not (1 <= count <= 10):
        await interaction.followup.send("Ch·ªâ t·ª´ 1-10 c√°i th√¥i bro")
        return
    
    async with aiohttp.ClientSession() as session:
        for i in range(count):
            async with session.get("https://phimtat.vn/api/random-meme/") as resp:
                if resp.status == 200:
                    embed = discord.Embed(title=f"Meme #{i+1}", color=random.randint(0, 0xFFFFFF))
                    embed.set_image(url=str(resp.url))
                    await interaction.followup.send(embed=embed)
                else:
                    await interaction.followup.send("L·ªói t·∫£i meme")
                    break

@bot.tree.command(name="8ball", description="H·ªèi yes/no")
@app_commands.describe(question="H·ªèi 1 c√¢u h·ªèi yes/no...")
async def eight_ball(interaction: discord.Interaction, question: str):
    responses = [
        "c√≥ nha üî•", "chx ƒë√¢u m ∆°i üíî", "c√≥ cl üò≠ü•Ä", "ch·∫Øc ch·∫Øn r·ªìi ƒë√≥ m üêßüíï",
        "ƒë·ª´ng m∆° n·ªØa üíÄ", "50/50 thoy üé≤", "h√™n xui ƒë√≥ m üòá", "next c√¢u kh√°c ƒëi ü•Ä",
        "t th·∫•y c√≥ v·∫ª kh·∫£ thi ƒë√≥ üëÄ", "ko nha, t·ªânh l·∫°i ƒëi m üêß"
    ]
    answer = random.choice(responses)
    
    embed = discord.Embed(title="üé± Magic 8-Ball", color=random.randint(0, 0xFFFFFF))
    embed.add_field(name="C√¢u h·ªèi", value=f"*{question}*", inline=False)
    embed.add_field(name="Tr·∫£ l·ªùi", value=f"**{answer}**", inline=False)
    embed.set_footer(text="GenniAI 8-Ball")
    
    await interaction.response.send_message(embed=embed)

@bot.tree.command(name="ship", description="Check OTP")
@app_commands.describe(user1="Ng∆∞·ªùi th·ª© 1", user2="Ng∆∞·ªùi th·ª© 2")
async def ship(interaction: discord.Interaction, user1: discord.Member = None, user2: discord.Member = None):
    await interaction.response.defer()
    members = [m for m in interaction.guild.members if not m.bot]
    
    if len(members) < 2:
        user1 = interaction.user
        user2 = interaction.user
        caption = "Server v·∫Øng, ship v·ªõi ch√≠nh m√†y ƒëi bro"
        match_pct = random.randint(70, 100)
    else:
        if user1 is None: user1 = random.choice(members)
        if user2 is None: user2 = random.choice([m for m in members if m != user1] or [user1])
        match_pct = random.randint(0, 100)
        
        if match_pct >= 90: caption = "OTP ƒë·ªânh, c∆∞·ªõi ƒëi üî•"
        elif match_pct >= 70: caption = "Match ch·∫•t, nh·∫Øn tin l·∫π üêß"
        elif match_pct >= 40: caption = "·ªîn ·ªïn... friendzone √° ü•Ä"
        else: caption = "Swipe left, next ƒëi üíÄ"
    
    embed = discord.Embed(title="Tinder Ship üî•", color=0xff69b4)
    embed.add_field(name="Ng∆∞·ªùi 1", value=f"{user1.display_name}", inline=True)
    embed.add_field(name="Ng∆∞·ªùi 2", value=f"{user2.display_name}", inline=True)
    embed.add_field(name="OTP", value=f"{match_pct}% - {caption}", inline=False)
    embed.set_footer(text=f"ƒë·ª´ng tin nha, k·∫øt qu·∫£ l√† ng·∫´u nhi√™n | server: {len(members)}")
    
    await interaction.followup.send(embed=embed)

@bot.tree.command(name="check_gay", description="ƒêo ƒë·ªô gay")
async def check_gay(interaction: discord.Interaction, target: discord.Member):
    rate = random.randint(0, 100)
    res = "Th·∫≥ng t·∫Øp lun √° broüî•" if rate < 35 else "Nghi m vlü•Ä" if rate <= 70 else "üè≥Ô∏è‚Äçüåà th·∫≠t r üò≠"
    await interaction.response.send_message(f"{target.display_name}: {rate}% - {res}")

# --- X·ª¨ L√ù CHAT ---
async def download_image(attachment):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(attachment.url) as resp:
                if resp.status == 200:
                    return base64.b64encode(await resp.read()).decode('utf-8')
    except:
        return None

@bot.event
async def on_message(message):
    if message.author == bot.user:
        return
    
    if bot.user.mentioned_in(message) or isinstance(message.channel, discord.DMChannel):
        user_id = str(message.author.id)
        
        # L·∫•y system prompt
        if user_id in custom_prompts:
            sys_msg = custom_prompts[user_id]
        else:
            sys_msg = system_instruction.replace(
                "<@1458799287910535324>", 
                f"<@{message.author.id}>"
            )
        
        # Kh·ªüi t·∫°o/update chat history
        if user_id not in chat_history:
            chat_history[user_id] = [{"role": "system", "content": sys_msg}]
        else:
            chat_history[user_id][0] = {"role": "system", "content": sys_msg}
        
        # Ki·ªÉm tra vision support
        config = MODELS_CONFIG[CURRENT_MODEL]
        has_img = len(message.attachments) > 0 and "image" in message.attachments[0].content_type
        
        if has_img and not config["vision"]:
            await message.reply(
                f"Model **{CURRENT_MODEL}** kh√¥ng h·ªó tr·ª£ vision.\n"
                f"D√πng l·ªánh `/model` ch·ªçn model c√≥ vision!"
            )
            return
        
        async with message.channel.typing():
            try:
                messages = chat_history[user_id].copy()
                
                # X·ª≠ l√Ω ·∫£nh n·∫øu c√≥
                if has_img:
                    img_b64 = await download_image(message.attachments[0])
                    if img_b64:
                        content = [
                            {"type": "text", "text": message.content or "Xem ·∫£nh"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}}
                        ]
                        messages.append({"role": "user", "content": content})
                    else:
                        await message.reply("L·ªói t·∫£i ·∫£nh")
                        return
                else:
                    messages.append({"role": "user", "content": message.content})
                
                # G·ªçi API
                reply = get_model_response(messages=messages, model_config=config)
                
                # X·ª≠ l√Ω response
                raw_reply = reply
                reply = raw_reply.split("</think>")[-1].strip() if "</think>" in raw_reply else raw_reply
                
                # L∆∞u history
                chat_history[user_id].append({"role": "user", "content": message.content or "[·∫¢nh]"})
                chat_history[user_id].append({"role": "assistant", "content": reply})
                chat_history[user_id] = chat_history[user_id][-8:]
                
                # G·ª≠i reply (KH√îNG C√ì ICON M√ÄU)
                await message.reply(reply or "T·ªãt r üíî")
                
            except Exception as e:
                await message.reply(f"L·ªói: {str(e)[:80]}")

if __name__ == "__main__":
    Thread(target=run_flask, daemon=True).start()
    bot.run(os.getenv("DISCORD_TOKEN"))