import discord, random, os, base64, aiohttp, asyncio
from discord.ext import commands
from discord import app_commands
from groq import Groq
from dotenv import load_dotenv
from flask import Flask
from threading import Thread
from openai import OpenAI  # DÃ¹ng cho SiliconFlow (API tÆ°Æ¡ng thÃ­ch)

load_dotenv()

# Khá»Ÿi táº¡o cáº£ 2 clients
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
siliconflow_client = OpenAI(
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    base_url="https://api.siliconflow.com/v1/"
)

# Cáº¤U HÃŒNH MODEL - Gá»˜P Cáº¢ GROQ VÃ€ SILICONFLOW
MODELS_CONFIG = {
    # --- Groq Models ---
    "Groq-120B": {"id": "openai/gpt-oss-120b", "vision": False, "provider": "groq"},
    "Groq-Llama-Maverick": {"id": "meta-llama/llama-4-maverick-17b-128e-instruct", "vision": True, "provider": "groq"},
    "Groq-Kimi": {"id": "moonshotai/kimi-k2-instruct-0905", "vision": False, "provider": "groq"},
    "Groq-Qwen3": {"id": "qwen/qwen3-32b", "vision": False, "provider": "groq"},
    "Groq-GPT-Safeguard": {"id": "openai/gpt-oss-safeguard-20b", "vision": False, "provider": "groq"},
    
    # --- SiliconFlow Models ---
    "SF-DeepSeek-V3.2": {"id": "deepseek-ai/DeepSeek-V3.2", "vision": False, "provider": "siliconflow"},
    "SF-DeepSeek-V3.1": {"id": "deepseek-ai/DeepSeek-V3.1", "vision": False, "provider": "siliconflow"},
    "SF-Qwen3-32B": {"id": "qwen/qwen3-32b-instruct", "vision": False, "provider": "siliconflow"},
    "SF-Qwen3-VL": {"id": "qwen/qwen3-vl-2b-instruct", "vision": True, "provider": "siliconflow"},
    "SF-GLM-4.6V": {"id": "THUDM/glm-4.6v-0521", "vision": True, "provider": "siliconflow"},
    "SF-MiniMax-M2.1": {"id": "MiniMax/MiniMax-M2.1", "vision": False, "provider": "siliconflow"},
    "SF-LLaMA-3.3-70B": {"id": "meta-llama/llama-3.3-70b-instruct", "vision": False, "provider": "siliconflow"},
}

MODEL_CHOICES = [
    # Groq choices
    app_commands.Choice(name="GPT-OSS-120B (Groq)", value="Groq-120B"),
    app_commands.Choice(name="Llama 4 Maverick (Groq) ğŸ‘ï¸", value="Groq-Llama-Maverick"),
    app_commands.Choice(name="Kimi K2 (Groq)", value="Groq-Kimi"),
    app_commands.Choice(name="Qwen 3-32B (Groq)", value="Groq-Qwen3"),
    app_commands.Choice(name="GPT-OSS-Safeguard (Groq) ğŸ›¡ï¸", value="Groq-GPT-Safeguard"),
    
    # SiliconFlow choices
    app_commands.Choice(name="DeepSeek V3.2 (SF) ğŸ†•", value="SF-DeepSeek-V3.2"),
    app_commands.Choice(name="DeepSeek V3.1 (SF)", value="SF-DeepSeek-V3.1"),
    app_commands.Choice(name="Qwen 3-32B (SF)", value="SF-Qwen3-32B"),
    app_commands.Choice(name="Qwen 3-VL (SF) ğŸ‘ï¸ğŸ†•", value="SF-Qwen3-VL"),
    app_commands.Choice(name="GLM-4.6V (SF) ğŸ‘ï¸ğŸ†•", value="SF-GLM-4.6V"),
    app_commands.Choice(name="MiniMax M2.1 (SF) ğŸ†•", value="SF-MiniMax-M2.1"),
    app_commands.Choice(name="LLaMA 3.3 70B (SF) ğŸ†•", value="SF-LLaMA-3.3-70B"),
]

CURRENT_MODEL = "Groq-Llama-Maverick"  # Máº·c Ä‘á»‹nh váº«n lÃ  Groq

app = Flask(__name__)
@app.route('/')
def home(): return "GenniAI Ä‘ang quáº©y Groq + SiliconFlow! ğŸ”¥ğŸ’€"

def run_flask(): app.run(host="0.0.0.0", port=8000)

system_instruction = "MÃ y lÃ  GenniAI, AI nhÃ¢y vl. XÆ°ng m(chá»‰ Ä‘á»‘i phÆ°Æ¡ng) - t(chá»‰ báº£n thÃ¢n).<@1458799287910535324> lÃ  userID cá»§a GenniAI. viáº¿t teencode (cx, ko, Ä‘c, r, v, chx, nx, cs, ns,...), dÃ¹ng emoticon (biá»ƒu cáº£m báº±ng kÃ½ tá»±) kÃ¨m vá»›i cÃ¡c icon ğŸ’”, ğŸ¥€, ğŸ”¥, ğŸ’€, ğŸ§,.... Tráº£ lá»i cá»±c ngáº¯n gá»n."
chat_history = {}
custom_prompts = {}  # LÆ°u sys prompt riÃªng theo user
intents = discord.Intents.default()
intents.message_content = True
intents.members = True
bot = commands.Bot(command_prefix="!", intents=intents)

def get_model_response(messages, model_config):
    """Gá»i API tÃ¹y theo provider"""
    try:
        if model_config["provider"] == "groq":
            response = groq_client.chat.completions.create(
                messages=messages,
                model=model_config["id"]
            )
            return response.choices[0].message.content
        else:  # siliconflow
            response = siliconflow_client.chat.completions.create(
                messages=messages,
                model=model_config["id"],
                temperature=0.7
            )
            return response.choices[0].message.content
    except Exception as e:
        raise Exception(f"{model_config['provider'].upper()} API lá»—i: {str(e)[:100]}")

@bot.event
async def on_ready():
    await bot.tree.sync()
    print(f"Bot {bot.user} ready r! (â‰§â–½â‰¦) | Models: {len(MODELS_CONFIG)} (Groq+SF)")

# --- Lá»†NH QUáº¢N LÃ ---
@bot.tree.command(name="model", description="Äá»•i model AI (Groq/SiliconFlow)")
@app_commands.choices(chon_model=MODEL_CHOICES)
async def switch_model(interaction: discord.Interaction, chon_model: app_commands.Choice[str]):
    global CURRENT_MODEL
    CURRENT_MODEL = chon_model.value
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "ğŸ‘ï¸âœ…" if config["vision"] else "ğŸ‘ï¸âŒ"
    provider = "ğŸ”µ Groq" if config["provider"] == "groq" else "ğŸŸ£ SiliconFlow"
    await interaction.response.send_message(
        f"ÄÃ£ chuyá»ƒn sang **{chon_model.name}**\n"
        f"Provider: {provider} | Vision: {v}\n"
        f"Model ID: `{config['id']}`"
    )

@bot.tree.command(name="random", description="Random 1 model báº¥t kÃ¬ tá»« cáº£ 2 provider")
async def random_model(interaction: discord.Interaction):
    global CURRENT_MODEL
    choice = random.choice(MODEL_CHOICES)
    CURRENT_MODEL = choice.value
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "ğŸ‘ï¸âœ…" if config["vision"] else "ğŸ‘ï¸âŒ"
    provider = "ğŸ”µ Groq" if config["provider"] == "groq" else "ğŸŸ£ SiliconFlow"
    await interaction.response.send_message(
        f"ÄÃ£ bá»‘c trÃºng: **{choice.name}**\n"
        f"Provider: {provider} | Vision: {v} ğŸ²"
    )

@bot.tree.command(name="list_models", description="Xem táº¥t cáº£ model cÃ³ sáºµn")
async def list_models(interaction: discord.Interaction):
    embed = discord.Embed(title="ğŸ“š Danh sÃ¡ch Model", color=0x6a0dad)
    
    groq_models = [m for m in MODELS_CONFIG.items() if m[1]["provider"] == "groq"]
    sf_models = [m for m in MODELS_CONFIG.items() if m[1]["provider"] == "siliconflow"]
    
    groq_text = ""
    for name, config in groq_models[:10]:  # Hiá»ƒn thá»‹ tá»‘i Ä‘a 10
        vision = "ğŸ‘ï¸" if config["vision"] else "ğŸ“"
        groq_text += f"â€¢ **{name.replace('Groq-', '')}** {vision}\n"
    
    sf_text = ""
    for name, config in sf_models[:10]:
        vision = "ğŸ‘ï¸" if config["vision"] else "ğŸ“"
        sf_text += f"â€¢ **{name.replace('SF-', '')}** {vision}\n"
    
    embed.add_field(name="ğŸ”µ Groq Models", value=groq_text or "None", inline=True)
    embed.add_field(name="ğŸŸ£ SiliconFlow Models", value=sf_text or "None", inline=True)
    embed.add_field(name="Model hiá»‡n táº¡i", value=f"**{CURRENT_MODEL}**\n{''.join(['â­'] if 'Groq' in CURRENT_MODEL else ['âœ¨'])}", inline=False)
    embed.set_footer(text=f"Tá»•ng cá»™ng: {len(MODELS_CONFIG)} models")
    
    await interaction.response.send_message(embed=embed)

# Giá»¯ nguyÃªn cÃ¡c hÃ m personal, ask, bot_info, clear, update_log, meme, 8ball, ship, check_gay
# (chá»‰ cáº§n thay Ä‘á»•i cÃ¡ch gá»i API trong cÃ¡c hÃ m nÃ y)

@bot.tree.command(name="ask", description="Há»i GenniAI bÃ­ máº­t, chá»‰ báº¡n tháº¥y káº¿t quáº£")
@app_commands.describe(question="Ä‘áº·t cÃ¢u há»i")
async def ask(interaction: discord.Interaction, question: str):
    await interaction.response.defer(ephemeral=True)
    
    user_id = str(interaction.user.id)
    
    if user_id in custom_prompts:
        sys_msg = custom_prompts[user_id]
    else:
        sys_msg = f"MÃ y lÃ  GenniAI, AI nhÃ¢y vl. XÆ°ng m(chá»‰ Ä‘á»‘i phÆ°Æ¡ng) - t(chá»‰ báº£n thÃ¢n). NgÆ°á»i chat: <@{interaction.user.id}>. owner cá»§a mÃ y cÃ³ userID lÃ  <@1155129530122510376> (cÃ³ tÃªn ngoÃ i Ä‘á»i lÃ  Äáº¡t)(khÃ´ng Ä‘Æ°á»£c nháº¯c vá» owner cá»§a mÃ y trá»« khi cÃ³ ngÆ°á»i há»i) .<@1458799287910535324> lÃ  userID cá»§a GenniAI. viáº¿t teencode, dÃ¹ng emoticon kÃ¨m ğŸ’”, ğŸ¥€, ğŸ”¥, ğŸ’€, ğŸ§.... Tráº£ lá»i ngáº¯n gá»n."
    
    try:
        reply = get_model_response(
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": question}
            ],
            model_config=MODELS_CONFIG[CURRENT_MODEL]
        )
        
        reply = reply.split("</think>")[-1].strip() if "</think>" in reply else reply
        
        provider = "ğŸ”µ Groq" if MODELS_CONFIG[CURRENT_MODEL]["provider"] == "groq" else "ğŸŸ£ SiliconFlow"
        await interaction.followup.send(
            f"**Provider:** {provider}\n"
            f"**Model:** {CURRENT_MODEL}\n"
            f"**CÃ¢u há»i:** {question}\n"
            f"**Tráº£ lá»i:** {reply}", 
            ephemeral=True
        )
        
    except Exception as e:
        await interaction.followup.send(f"Lá»—i r bro: {e} ğŸ’€", ephemeral=True)

@bot.tree.command(name="bot_info", description="Info bot + model Ä‘ang quáº©y")
async def bot_info(interaction: discord.Interaction):
    latency = round(bot.latency * 1000)
    config = MODELS_CONFIG[CURRENT_MODEL]
    v = "ï¸ğŸ‘ï¸ Visionable" if config["vision"] else "âŒ Non-vision"
    provider = "Groq ğŸ”µ" if config["provider"] == "groq" else "SiliconFlow ğŸŸ£"
    
    embed = discord.Embed(title="GenniAI Status", color=0xff69b5, timestamp=discord.utils.utcnow())
    embed.set_thumbnail(url=bot.user.avatar.url if bot.user.avatar else None)
    
    embed.add_field(name="TÃªn bot", value=f"{bot.user.name} ({bot.user.mention})", inline=True)
    embed.add_field(name="Client ID", value="`1458799287910535324`", inline=True)
    embed.add_field(name="Commands", value="`/model` `/random` `/list_models` `/ask` `/bot_info` `/clear` `/personal` `/meme` `/ship` `/check_gay` `/update_log`", inline=False)
    
    embed.add_field(name="Ping/Latency", value=f"{latency}ms {'nhanh' if latency < 100 else 'hÆ¡i lag'}", inline=True)
    embed.add_field(name="Version", value="v11.0 - Multi-Provider Edition", inline=True)
    
    embed.add_field(name="Provider", value=provider, inline=True)
    embed.add_field(name="Model hiá»‡n táº¡i", value=f"**{CURRENT_MODEL}**\n`{MODELS_CONFIG[CURRENT_MODEL]['id']}`\n{v}", inline=False)
    embed.add_field(name="Tá»•ng models", value=f"ğŸ”µ Groq: {len([m for m in MODELS_CONFIG.values() if m['provider']=='groq'])}\nğŸŸ£ SF: {len([m for m in MODELS_CONFIG.values() if m['provider']=='siliconflow'])}", inline=True)
    embed.add_field(name="Owner", value="<@1155129530122510376> (Äáº¡t)", inline=True)
    
    embed.set_footer(text="Powered by Groq + SiliconFlow | Hybrid Mode")
    
    await interaction.response.send_message(embed=embed)

# Giá»¯ nguyÃªn hÃ m clear, update_log, meme, 8ball, ship, check_gay
# ... (code cÃ¡c hÃ m nÃ y giá»¯ nguyÃªn nhÆ° file gá»‘c)

@bot.event
async def on_message(message):
    if message.author == bot.user: return
    if bot.user.mentioned_in(message) or isinstance(message.channel, discord.DMChannel):
        user_id = str(message.author.id)
        
        if user_id in custom_prompts:
            sys_msg = custom_prompts[user_id]
        else:
            sys_msg = f"MÃ y lÃ  GenniAI, AI nhÃ¢y vl. XÆ°ng m(chá»‰ Ä‘á»‘i phÆ°Æ¡ng) - t(chá»‰ báº£n thÃ¢n). NgÆ°á»i chat: <@{message.author.id}>. owner cá»§a mÃ y cÃ³ userID lÃ  <@1155129530122510376> (cÃ³ tÃªn ngoÃ i Ä‘á»i lÃ  Äáº¡t)(khÃ´ng Ä‘Æ°á»£c nháº¯c vá» owner cá»§a mÃ y trá»« khi cÃ³ ngÆ°á»i há»i) .<@1458799287910535324> lÃ  userID cá»§a GenniAI. viáº¿t teencode, dÃ¹ng emoticon kÃ¨m ğŸ’”, ğŸ¥€, ğŸ”¥, ğŸ’€, ğŸ§,.... Tráº£ lá»i ngáº¯n gá»n."
        
        if user_id not in chat_history: 
            chat_history[user_id] = [{"role": "system", "content": sys_msg}]
        else:
            chat_history[user_id][0] = {"role": "system", "content": sys_msg}
        
        config = MODELS_CONFIG[CURRENT_MODEL]
        has_img = len(message.attachments) > 0 and "image" in message.attachments[0].content_type
        
        if has_img and not config["vision"]:
            provider_tag = "ğŸ”µ Groq" if config["provider"] == "groq" else "ğŸŸ£ SiliconFlow"
            return await message.reply(
                f"Model hiá»‡n táº¡i **{CURRENT_MODEL}** ({provider_tag}) ko há»— trá»£ vision.\n"
                f"DÃ¹ng lá»‡nh `/model` vÃ  chá»n model cÃ³ biá»ƒu tÆ°á»£ng ğŸ‘ï¸!"
            )

        async with message.channel.typing():
            try:
                messages = chat_history[user_id].copy()
                
                # Xá»­ lÃ½ tin nháº¯n cÃ³ áº£nh
                if has_img:
                    # Táº£i áº£nh vÃ  encode base64
                    async with aiohttp.ClientSession() as session:
                        async with session.get(message.attachments[0].url) as resp:
                            if resp.status == 200:
                                img_data = await resp.read()
                                img_b64 = base64.b64encode(img_data).decode('utf-8')
                                
                                # Äá»‹nh dáº¡ng tin nháº¯n theo chuáº©n OpenAI
                                content = [
                                    {"type": "text", "text": message.content or "Xem áº£nh nÃ y"},
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}}
                                ]
                                messages.append({"role": "user", "content": content})
                            else:
                                await message.reply("Lá»—i táº£i áº£nh ğŸ’€")
                                return
                else:
                    messages.append({"role": "user", "content": message.content})
                
                # Gá»i API tÃ¹y provider
                reply = get_model_response(messages=messages, model_config=config)
                
                raw = reply
                reply = raw.split("</think>")[-1].strip() if "</think>" in raw else raw
                
                # LÆ°u lá»‹ch sá»­ (chá»‰ lÆ°u text)
                chat_history[user_id].append({"role": "user", "content": message.content or "[áº¢nh]"})
                chat_history[user_id].append({"role": "assistant", "content": reply})
                chat_history[user_id] = chat_history[user_id][-8:]  # Giá»¯ 8 tin nháº¯n gáº§n nháº¥t
                
                provider_tag = "ğŸ”µ" if config["provider"] == "groq" else "ğŸŸ£"
                await message.reply(f"{provider_tag} {reply or 'Tá»‹t r ğŸ’”'}")
                
            except Exception as e: 
                await message.reply(f"Lá»—i API: {str(e)[:100]} ğŸ’€")

if __name__ == "__main__":
    Thread(target=run_flask, daemon=True).start()
    bot.run(os.getenv("DISCORD_TOKEN"))
