import discord
from discord.ext import commands
from discord import app_commands
from groq import Groq
from openai import OpenAI
import os, urllib.parse
from dotenv import load_dotenv
from flask import Flask
from threading import Thread

load_dotenv()

# --- KH·ªûI T·∫†O SDK (Vƒ©nh bi·ªát Google Rate Limit ü•Ä) ---
# Groq cho m·∫•y con model m th√≠ch
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
# OpenRouter cho m·∫•y con h√†ng FREE
or_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
)

# 1. Config Model ID (th√™m free OpenRouter)
MODELS_CONFIG = {
    "120B": "openai/gpt-oss-120b",
    "Llama-Maverick": "meta-llama/llama-4-maverick-17b-128e-instruct",
    "Kimi": "moonshotai/kimi-k2-instruct-0905",
    "Llama-Free": "meta-llama/llama-3.1-8b-instruct:free",
    "MiMo-Flash": "xiaomi/mimo-v2-flash:free",          # vl x·ªãn, context 262k üî•
    "Devstral": "mistralai/devstral-2512:free",         # coding god free lu√¥n
    "Chimera-R1T2": "tngtech/deepseek-r1t2-chimera:free",  # roleplay/creepy ngon
    "LFM-Instruct": "liquid/lfm-2.5-1.2b-instruct:free"   # nh·ªè g·ªçn, chat nhanh
}

# 2. Danh s√°ch Model cho Slash Command (th√™m m·∫•y con free)
MODEL_CHOICES = [
    app_commands.Choice(name="GPT-OSS-120B (Groq)", value="120B"),
    app_commands.Choice(name="Llama 4 Maverick (Groq)", value="Llama-Maverick"),
    app_commands.Choice(name="Kimi K2 (Groq)", value="Kimi"),
    app_commands.Choice(name="Llama 3.1 8B (OpenRouter FREE)", value="Llama-Free"),
    app_commands.Choice(name="MiMo-V2-Flash (Free 262k ctx)", value="MiMo-Flash"),
    app_commands.Choice(name="Devstral 2 2512 (Coding Beast Free)", value="Devstral"),
    app_commands.Choice(name="DeepSeek R1T2 Chimera (Roleplay Free)", value="Chimera-R1T2"),
    app_commands.Choice(name="LFM 1.2B Instruct (Nh·ªè g·ªçn Free)", value="LFM-Instruct")
]

CURRENT_MODEL = "Kimi" 

# --- FLASK ƒê·ªÇ TREO BOT TR√äN KOYEB ---
app = Flask(__name__)
@app.route('/')
def home(): return "GenA-bot ƒëang 'qu·∫©y' Groq + OpenRouter free, n√© ra ko c·∫Øn! üî•üíÄ"

def run_flask():
    app.run(host="0.0.0.0", port=8000)

# --- CONFIG BOT ---
system_instruction = "M√†y l√† GenA-bot, AI nh√¢y vl. X∆∞ng m(m√†y) - t(tao), vi·∫øt teencode, d√πng icon üíî, ü•Ä, üî•, üíÄ, üêß,.... Tr·∫£ l·ªùi c·ª±c ng·∫Øn g·ªçn."

chat_history = {}
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

@bot.event
async def on_ready():
    await bot.tree.sync()
    print(f"Bot {bot.user} ready c·∫Øn m r! (‚âß‚ñΩ‚â¶)")

# --- L·ªÜNH SLASH ƒê·ªîI MODEL ---
@bot.tree.command(name="model", description="ƒê·ªïi model AI ƒë·ªÉ chat")
@app_commands.choices(chon_model=MODEL_CHOICES)
async def switch_model(interaction: discord.Interaction, chon_model: app_commands.Choice[str]):
    global CURRENT_MODEL
    CURRENT_MODEL = chon_model.value
    await interaction.response.send_message(f"ƒê√£ chuy·ªÉn sang model **{chon_model.name}** th√†nh c√¥ng")

# --- L·ªÜNH SLASH V·∫º ·∫¢NH ---
@bot.tree.command(name="imagine", description="V·∫Ω ·∫£nh b·∫±ng AI")
async def imagine(interaction: discord.Interaction, prompt: str):
    await interaction.response.defer()
    encoded = urllib.parse.quote(prompt)
    url = f"https://image.pollinations.ai/prompt/{encoded}?width=1024&height=1024&nologo=true"
    embed = discord.Embed(title="H√†ng v·ªÅ!", description=f"Prompt: `{prompt}`", color=0xff69b4)
    embed.set_image(url=url)
    await interaction.followup.send(embed=embed)

# --- X·ª¨ L√ù CHAT ---
@bot.event
async def on_message(message):
    if message.author == bot.user: return
    if bot.user.mentioned_in(message) or isinstance(message.channel, discord.DMChannel):
        user_id = str(message.author.id)
        if user_id not in chat_history:
            chat_history[user_id] = [{"role": "system", "content": system_instruction}]
        
        chat_history[user_id].append({"role": "user", "content": message.content})
        
        try:
            async with message.channel.typing():
                model_id = MODELS_CONFIG[CURRENT_MODEL]
                
                # Logic ch·ªçn SDK
                if CURRENT_MODEL in ["120B", "Llama-Maverick", "Kimi"]:
                    # D√πng Groq SDK
                    chat_completion = groq_client.chat.completions.create(
                        messages=chat_history[user_id],
                        model=model_id,
                        temperature=0.7
                    )
                    reply = chat_completion.choices[0].message.content
                else:
                    # D√πng OpenRouter SDK (cho t·∫•t c·∫£ free + Llama-Free)
                    res = or_client.chat.completions.create(
                        model=model_id,
                        messages=chat_history[user_id]
                    )
                    reply = res.choices[0].message.content
                
                await message.reply(reply if reply else "GAH DAYUMüíîüò≠üôè")
        except Exception as e:
            await message.reply(f"L·ªói clgi r m ∆°i... üíÄ: {e}")

if __name__ == "__main__":
    Thread(target=run_flask, daemon=True).start()
    bot.run(os.getenv("DISCORD_TOKEN"))
